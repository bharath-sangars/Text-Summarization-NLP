{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4208ce6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\sanga\\anaconda3\\lib\\site-packages (23.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9798654",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fc0e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in c:\\users\\sanga\\anaconda3\\lib\\site-packages (2.14.0.dev20230618)\n",
      "Requirement already satisfied: tf-nightly-intel==2.14.0-dev20230618 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly) (2.14.0.dev20230618)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.22.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.20.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (61.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (4.1.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.54.2)\n",
      "Requirement already satisfied: tb-nightly~=2.14.0.a in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.14.0a20230618)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.14.0.dev in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.14.0.dev2023061808)\n",
      "Requirement already satisfied: keras-nightly~=2.14.0.dev in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.14.0.dev2023061807)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from packaging->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.26.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sanga\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tb-nightly~=2.14.0.a->tf-nightly-intel==2.14.0-dev20230618->tf-nightly) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42d4ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sanga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a5090ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset cnn_dailymail (C:/Users/Sanga/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e12c4e1a70444ab8f4bf149fa8f05d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", version =\"3.0.0\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "380e913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features in cnn_dailymail :['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "print(f\"features in cnn_dailymail :{dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44c502f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (287113, 3), 'validation': (13368, 3), 'test': (11490, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eccb898d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8cdc803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article (excerpt of 500 characters, total length: 4051):\n",
      "\n",
      "\n",
      "Summary (length: 281):\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 characters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3136817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset[\"train\"][1][\"article\"][:2000]\n",
    "\n",
    "# We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46522f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_summary_three_sent(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5d78815",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries['baseline'] = baseline_summary_three_sent(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "546447fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "pipe = pipeline('text-generation', model = 'gpt2-medium' )\n",
    "\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "\n",
    "pipe_out = pipe(gpt2_query, max_length = 512, clean_up_tokenization_spaces = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3620b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Editor\\'s note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events. Here, Soledad O\\'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here, inmates with the most severe mental illnesses are incarcerated until they\\'re ready to appear in court. Most often, they face drug charges or charges of assaulting an officer --charges that Judge Steven Leifman says are usually \"avoidable felonies.\" He says the arrests often result from confrontations with police. Mentally ill people often won\\'t do what they\\'re told when police arrive on the scene -- confrontation seems to exacerbate their illness and they become more paranoid, delusional, and less likely to follow directions, according to Leifman. So, they end up on the ninth floor severely mentally disturbed, but not getting any real help because they\\'re in jail. We toured the jail with Leifman. He is well known in Miami as an advocate for justice and the mentally ill. Even though we were not exactly welcomed with open arms by the guards, we were given permission to shoot videotape and tour the floor.  Go inside the \\'forgotten floor\\' Â» . At first, it\\'s hard to determine where the people are. The prisoners are wearing sleeveless robes. Imagine cutting holes for arms and feet in a heavy wool sleeping bag -- that\\'s kind of what they look like. They\\'re designed to keep the mentally ill patients from injuring themselves. That\\'s also why they have no shoes, laces or mattresses. Leifman says about one-third of all people in Miami-Dade county jails are mentally ill. So, he says, the sheer volume is overwhelming the system, and the result is what we see on the ninth floor. Of course, it is a jail, so it\\'s \\nTL;DR:\\n- Prisoners are wearing sleeveless prison clothes with holes cut into the tops. The holes fit on them and they can\\'t walk. People are unable to properly control their emotions and the prison environment can become a nightmare. -\\n- Most people in state prisons in Florida are mentally ill. \\n- The hole in their top has been cut off at wrist level and now leads'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c5691fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- Prisoners are wearing sleeveless prison clothes with holes cut into the tops. The holes fit on them and they can't walk. People are unable to properly control their emotions and the prison environment can become a nightmare. -\\n- Most people in state prisons in Florida are mentally ill. \\n- The hole in their top has been cut off at wrist level and now leads\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_out[0][\"generated_text\"][len(gpt2_query) :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2046a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"- Prisoners are wearing sleeveless prison clothes with holes cut into the tops.\\nThe holes fit on them and they can't walk.\\nPeople are unable to properly control their emotions and the prison environment can become a nightmare.\\n-\\n- Most people in state prisons in Florida are mentally ill. \\n- The hole in their top has been cut off at wrist level and now leads\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries['gpt2'] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query) :]))\n",
    "summaries['gpt2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e04e1879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\"\n",
      "GPT2\n",
      "- Prisoners are wearing sleeveless prison clothes with holes cut into the tops.\n",
      "The holes fit on them and they can't walk.\n",
      "People are unable to properly control their emotions and the prison environment can become a nightmare.\n",
      "-\n",
      "- Most people in state prisons in Florida are mentally ill. \n",
      "- The hole in their top has been cut off at wrist level and now leads\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "\n",
    "print(dataset['train'][1]['highlights'])\n",
    "\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae73c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_on_baseline_test_ds(dataset, metric, column_text = 'article', column_summary = 'highlights' ):\n",
    "   \n",
    "    summaries = [baseline_summary_three_sent(text) for text in dataset[column_text] ]\n",
    "\n",
    "    metric.add_batch(predictions = summaries, references = dataset[column_summary] )\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0f03d718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at C:\\Users\\Sanga\\.cache\\huggingface\\datasets\\cnn_dailymail\\default\\3.0.0\\1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de\\cache-c98764b7079899be.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.253995</td>\n",
       "      <td>0.100642</td>\n",
       "      <td>0.165754</td>\n",
       "      <td>0.231571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.253995  0.100642  0.165754   0.231571"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset['train'].shuffle(seed = 42).select(range(1000))\n",
    "\n",
    "score = calculate_metric_on_baseline_test_ds(test_sampled, rouge_metric )\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "\n",
    "pd.DataFrame.from_dict(rouge_dict, orient = 'index' , columns = ['baseline'] ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d353f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[12, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[79, 78, 77, 76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[15.189873417721518, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>[15.19, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Value\n",
       "score                                       0.0\n",
       "counts                            [12, 0, 0, 0]\n",
       "totals                         [79, 78, 77, 76]\n",
       "precisions  [15.189873417721518, 0.0, 0.0, 0.0]\n",
       "bp                                          1.0\n",
       "sys_len                                      79\n",
       "ref_len                                      57\n",
       "precision                [15.19, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_metric = load_metric(\"sacrebleu\")\n",
    "bleu_metric.add(prediction = [summaries[\"gpt2\"]], reference = [dataset['train'][1]['highlights'] ])\n",
    "\n",
    "results = bleu_metric.compute(smooth_method = 'floor', smooth_value = 0 )\n",
    "\n",
    "results['precision'] = [np.round(p , 2) for p in results['precisions'] ]\n",
    "\n",
    "pd.DataFrame.from_dict(results, orient = 'index', columns = ['Value'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9dbcf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge_dict  {'rouge1': 0.365079365079365, 'rouge2': 0.14516129032258066, 'rougeL': 0.20634920634920634, 'rougeLsum': 0.2857142857142857}\n",
      "rouge_dict  {'rouge1': 0.23214285714285715, 'rouge2': 0.018181818181818184, 'rougeL': 0.125, 'rougeLsum': 0.2142857142857143}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.232143  0.018182  0.125000   0.214286"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_metric = load_metric('rouge')\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "reference = dataset['train'][1]['highlights']\n",
    "\n",
    "records = []\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction = summaries[model_name], reference = reference )\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
    "    print('rouge_dict ', rouge_dict )\n",
    "    records.append(rouge_dict)\n",
    "\n",
    "pd.DataFrame.from_records(records, index = summaries.keys() )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
